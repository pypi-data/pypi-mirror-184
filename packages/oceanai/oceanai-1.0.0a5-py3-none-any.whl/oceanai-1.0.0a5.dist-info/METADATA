Metadata-Version: 2.1
Name: oceanai
Version: 1.0.0a5
Summary: OCEANAI
Home-page: https://github.com/DmitryRyumin/oceanai
Author: Elena Ryumina, Dmitry Ryumin, Alexey Karpov
Author-email: ryumina_ev@mail.ru, dl_03.03.1991@mail.ru, karpov@iias.spb.su
Maintainer: Elena Ryumina, Dmitry Ryumin
Maintainer-email: ryumina_ev@mail.ru, dl_03.03.1991@mail.ru
License: BSD License
Project-URL: Bug Reports, https://github.com/DmitryRyumin/oceanai/issues
Project-URL: Documentation, https://oceanai.readthedocs.io
Project-URL: Source Code, https://github.com/DmitryRyumin/oceanai/tree/main/oceanai
Project-URL: Download, https://github.com/DmitryRyumin/oceanai/tags
Keywords: OCEAN-AI,MachineLearning,Statistics,ComputerVision,ArtificialIntelligence,Preprocessing
Classifier: Development Status :: 3 - Alpha
Classifier: Natural Language :: Russian
Classifier: Natural Language :: English
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: End Users/Desktop
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Information Technology
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: BSD License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Image Processing
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Documentation
Classifier: Topic :: Documentation :: Sphinx
Classifier: Topic :: Multimedia :: Sound/Audio
Classifier: Topic :: Multimedia :: Sound/Audio :: Analysis
Classifier: Topic :: Multimedia :: Sound/Audio :: Speech
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Software Development :: Localization
Classifier: Topic :: Utilities
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Operating System :: Microsoft :: Windows
Classifier: Operating System :: POSIX :: Linux
Classifier: Framework :: Jupyter
Classifier: Framework :: Jupyter :: JupyterLab :: 4
Classifier: Framework :: Sphinx
Requires-Python: >=3.9, <4
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: ipython (>=8.7.0)
Requires-Dist: jupyterlab (>=3.5.0)
Requires-Dist: tensorflow (>=2.11.0)
Requires-Dist: keras (>=2.11.0)
Requires-Dist: Keras-Applications (>=1.0.8)
Requires-Dist: numpy (>=1.23.5)
Requires-Dist: scipy (>=1.9.3)
Requires-Dist: pandas (>=1.5.2)
Requires-Dist: requests (>=2.28.1)
Requires-Dist: opensmile (>=2.4.1)
Requires-Dist: librosa (>=0.9.2)
Requires-Dist: audioread (>=3.0.0)
Requires-Dist: scikit-learn (>=1.1.3)
Requires-Dist: opencv-contrib-python (>=4.6.0.66)
Requires-Dist: pymediainfo (>=6.0.1)
Requires-Dist: mediapipe (>=0.9.0)

# [OCEANAI](https://github.com/DmitryRyumin/ocean)

![PyPI](https://img.shields.io/pypi/v/oceanai)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/oceanai)
![PyPI - Implementation](https://img.shields.io/pypi/implementation/oceanai)
![GitHub repo size](https://img.shields.io/github/repo-size/dmitryryumin/oceanai)
![PyPI - Status](https://img.shields.io/pypi/status/oceanai)
![PyPI - License](https://img.shields.io/pypi/l/oceanai)
![GitHub top language](https://img.shields.io/github/languages/top/dmitryryumin/oceanai)
![Documentation Status](https://readthedocs.org/projects/oceanai/badge/?version=latest)

---

| [Documentation in Russian](https://github.com/DmitryRyumin/oceanai/blob/main/README_RU.md) |
|--------------------------------------------------------------------------------------------|

---

<h4 align="center"><span style="color:#EC256F;">Description</span></h4>

---

>  **[OCEANAI](https://github.com/DmitryRyumin/oceanai)** is an open-source library consisting of a set of algorithms for intellectual analysis of human behavior based on multimodal data for automatic personal traits assessment to performance of professional duties. The library evaluates 5 traits: **O**penness to experience, **C**onscientiousness, **E**xtraversion, **A**greeableness, **N**euroticism.

---

**[OCEANAI](https://github.com/DmitryRyumin/oceanai)** includes three main algorithms:

1. Audio Information Analysis Algorithm (AIA).
2. Video Information Analysis Algorithm (VIA).
3. Multimodal Fusion Algorithm (MF).

The AIA and VIA algorithms implement the functions of strong artificial intelligence (AI) in terms of complexing acoustic and visual features built on different principles (expert and neural network), i.e. these algorithms implement the approaches of composite (hybrid) AI. The necessary pre-processing is carried out in the algorithms audio and video information, the calculation of visual and acoustic features and the issuance of prediction personality traits based on them.

The MF algorithm is a link between two information analysis algorithms (AIA and VIA). This algorithm performs a weighted neural network combination of prediction personality traits obtained using the AIA and VIA algorithms.

In addition to the main task - unimodal and multimodal personality traits assessment, the features implemented in **[OCEANAI](https://github.com/DmitryRyumin/oceanai)** will allow researchers to solve other problems of analyzing human behavior, for example, recognizing his affective states.

To install the library, you should refer to the **[Installation and Update](https://oceanai.readthedocs.io/en/latest/user_guide/installation.html#id2)**.

To work with audio information, you should refer to the **[Audio information processing](https://oceanai.readthedocs.io/en/latest/user_guide/samples/audio.html)**.

To work with video information, you should refer to the **[Video information processing](https://oceanai.readthedocs.io/en/latest/user_guide/samples/video.html)**.

To work with audio-visual information, you should refer to the **[Multimodal information processing](https://oceanai.readthedocs.io/en/latest/user_guide/samples/multimodal.html)**.

The library solves practical tasks:

1. **[Ranking of potential candidates by professional responsibilities](https://oceanai.readthedocs.io/en/latest/user_guide/notebooks/Pipeline_practical_task_1.html)**.
2. **[Predicting consumer preferences for industrial goods](https://oceanai.readthedocs.io/en/latest/user_guide/notebooks/Pipeline_practical_task_2.html)**.

**[OCEANAI](https://github.com/DmitryRyumin/oceanai)** uses the latest open-source libraries for audio and video processing: **[librosa](https://librosa.org/)**, **[openSMILE](https://audeering.github.io/opensmile-python/)**, **[openCV](https://pypi.org/project/opencv-python/)**, **[mediapipe](https://google.github.io/mediapipe/getting_started/python)**.

**[OCEANAI](https://github.com/DmitryRyumin/oceanai)** is written in the **[python programming language](https://www.python.org/)**. Neural network models are implemented and trained using an open-source library code **[TensorFlow](https://www.tensorflow.org/)**.
