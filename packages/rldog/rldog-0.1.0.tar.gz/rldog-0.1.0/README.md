# PyRL
Environment Agnostic RL algorithm implementations using Pytorch. High quality code, typehints, thorough tests, examples.
Also uses minibatches correctly, which most public libraries don't implement.


See examples for some, well, examples. Algos implemented:

1. *Deep Q Learning (DQN)* <sub><sup> ([Mnih et al. 2013](https://arxiv.org/pdf/1312.5602.pdf)) </sup></sub>  
 --- UPCOMING ---
2. *DQN Experience Replay*  <sub><sup> ([Mnih et al. 2013](https://arxiv.org/pdf/1312.5602.pdf)) </sup></sub> 
3. *DQN with Fixed targets* <sub><sup>([Mnih et al. 2013](https://arxiv.org/pdf/1312.5602.pdf)) </sup></sub> 
4. *Double Q Learning (DDQN)* <sub><sup> ([arXiv:1509.06461v3 [cs.LG] 8 Dec 2015](https://arxiv.org/pdf/1509.06461v3.pdf)) </sup></sub>   
5. REINFORCE <sub><sup> ([Richard S. Sutton et al 1999](https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf))
6. Advantage Actor Critic ([arXiv:1611.06256](https://arxiv.org/abs/1611.06256))

3. PPO

What i'm happy with
Quality of the code, thorough tests, majority of functionality, ease of use & versatility

Run tests with: pytest tests