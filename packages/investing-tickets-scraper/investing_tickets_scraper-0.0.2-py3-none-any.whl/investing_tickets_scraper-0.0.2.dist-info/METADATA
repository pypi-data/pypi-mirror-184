Metadata-Version: 2.1
Name: investing-tickets-scraper
Version: 0.0.2
Summary: Scraps stock tickets from "Investing.com" using Selenium and parse using BeautifulSoup
Home-page: UNKNOWN
Author: Lucas Rocha
Author-email: lucasrocha.png@gmail.com
License: UNKNOWN
Keywords: python,tickers,index,stocks,exchange,investing
Platform: UNKNOWN
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: Unix
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Operating System :: Microsoft :: Windows
Description-Content-Type: text/markdown
License-File: LICENSE.txt
Requires-Dist: beautifulsoup4 (>=4.4.1)
Requires-Dist: pandas (>=1.3.3)
Requires-Dist: selenium (>=4.1.3)

# investing-tickets-scraper
#### This package scraps all tickets available from "investing.com" site

## How to install
Installing "investing-tickets-scraper" from pypi (recomended).
```bash
pip install investing-tickets-scraper
```

## How to use

```python
# Import the library
from investing_tickets_scraper.scraper import Scraper
import pandas as pd

# Create the object scraper using the imported class
scraper = Scraper()

# Configurates the scraper
scraper.config(chromedriver_path="C:\Program Files (x86)\chromedriver.exe", # Chromedriver_path = chromedriver for Selenium, if you don't know what is it, check this video "https://youtu.be/Xjv1sY630Uc" and install it
                country="United States")  # Country = the country you want to scrap the tickeks. To check all countries available you can use "print(scraper.contries_available())"
                                                                                                      
# Start scraping
scraper.scrap() # It will open the Google Chrome and scrap it. Is recommended not to use the mouse and the keboard

# Return the data as a pandas dataframe
df = scraper.return_dataframe()
print(df) # df
```


