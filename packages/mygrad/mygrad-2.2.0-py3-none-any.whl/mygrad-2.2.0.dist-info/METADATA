Metadata-Version: 2.1
Name: mygrad
Version: 2.2.0
Summary: Brings drop-in automatic differentiation to NumPy
Home-page: https://github.com/rsokl/MyGrad
Download-URL: https://github.com/rsokl/mygrad/tarball/v2.2.0
Author: Ryan Soklaski
Author-email: rsoklaski@gmail.com
License: MIT
Classifier: Development Status :: 5 - Production/Stable
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Education
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Topic :: Scientific/Engineering
Requires-Python: >=3.7
License-File: LICENSE.txt
Requires-Dist: numpy (>=1.20)
Provides-Extra: rnn
Requires-Dist: numba (>=0.34.0) ; extra == 'rnn'


MyGrad is a lightweight library that adds automatic differentiation to NumPy â€“ its only dependency is NumPy!
It's primary goal is to make automatic differentiation an accessible and easy to use across the Python/NumPy ecosystem.

MyGrad introduces a tensor object, which behaves like NumPy's ndarray object, but that builds a computational
graph, which enables MyGrad to perform reverse-mode differentiation (i.e. "backpropagation"). By exploiting
NumPy's mechanisms for ufunc/function overrides, MyGrad's tensor works "natively" with NumPy's suite of mathematical
functions so that they can be chained together into a differentiable computational graph.

NumPy's systems for broadcasting operations, producing views of arrays, performing in-place operations, and permitting
both "basic" and "advanced" indexing of arrays are all supported by MyGrad to a high-fidelity.
